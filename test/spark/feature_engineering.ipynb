{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Glue - Feature Engineering Job\n",
    "\n",
    "**功能**: 基于清洗数据生成机器学习特征\n",
    "\n",
    "**输入**: cleaned_customer_base, cleaned_customer_behavior\n",
    "**输出**: customer_features (包含所有计算特征)\n",
    "\n",
    "**特征包括**:\n",
    "- RFM分析 (Recency, Frequency, Monetary)\n",
    "- 客户生命周期评分\n",
    "- 行为活跃度评分\n",
    "- 产品交叉销售指数\n",
    "- 客户价值评分"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 环境配置"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T02:47:29.340071Z",
     "start_time": "2025-12-08T02:47:29.322043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import spark\n",
    "\n",
    "# Ensure environment variables are set\n",
    "if 'JAVA_HOME' not in os.environ:\n",
    "    java_home = \"C:\\\\Program Files\\\\Java\\\\jdk-11\"\n",
    "    os.environ['JAVA_HOME'] = java_home\n",
    "\n",
    "if 'SPARK_HOME' not in os.environ:\n",
    "    spark_home = \"C:\\\\Users\\\\hy120\\\\spark\\\\spark-3.5.7-bin-hadoop3\"\n",
    "    os.environ['SPARK_HOME'] = spark_home\n",
    "\n",
    "# 设置 HADOOP_HOME 指向你的 Hadoop 安装目录\n",
    "os.environ[\"HADOOP_HOME\"] = \"C:\\\\Users\\\\hy120\\\\hadoop\"\n",
    "os.environ[\"HADOOP_COMMON_HOME\"] = \"C:\\\\Users\\\\hy120\\\\hadoop\"\n",
    "os.environ[\"HADOOP_HDFS_HOME\"] = \"C:\\\\Users\\\\hy120\\\\hadoop\"\n",
    "os.environ[\"HADOOP_MAPRED_HOME\"] = \"C:\\\\Users\\\\hy120\\\\hadoop\"\n",
    "os.environ[\"HADOOP_YARN_HOME\"] = \"C:\\\\Users\\\\hy120\\\\hadoop\"\n",
    "os.environ[\"HADOOP_CONF_DIR\"] = \"C:\\\\Users\\\\hy120\\\\hadoop\\\\etc\\\\hadoop\"\n",
    "\n",
    "# 让 Spark executor 和 driver 都用当前这个 Python（你的 .venv 里的 python）\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
    "\n",
    "print(\"Environment setup:\")\n",
    "print(\"  JAVA_HOME:\", os.environ.get(\"JAVA_HOME\"))\n",
    "print(\"  SPARK_HOME:\", os.environ.get(\"SPARK_HOME\"))\n",
    "print(\"  PYSPARK_PYTHON:\", os.environ.get(\"PYSPARK_PYTHON\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup:\n",
      "  JAVA_HOME: C:\\Program Files\\Java\\jdk-11\n",
      "  SPARK_HOME: C:\\Users\\hy120\\spark\\spark-3.5.7-bin-hadoop3\n",
      "  PYSPARK_PYTHON: C:\\Users\\hy120\\Downloads\\zhihullm\\CASE-customer-group\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 导入必要的库"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T02:47:41.976012Z",
     "start_time": "2025-12-08T02:47:41.962570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import (\n",
    "    col, when, sum as spark_sum, avg, max as spark_max, min as spark_min,\n",
    "    row_number, rank, dense_rank, ntile,\n",
    "    datediff, months_between, year, month,\n",
    "    round, log, sqrt, abs as spark_abs,\n",
    "    lit, coalesce, first, last\n",
    ")\n",
    "\n",
    "# 配置日志\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Spark会话配置"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T02:48:27.598387Z",
     "start_time": "2025-12-08T02:48:27.566356Z"
    }
   },
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import (\n",
    "    col, when, sum as spark_sum, avg, max as spark_max, min as spark_min,\n",
    "    row_number, rank, dense_rank, ntile,\n",
    "    datediff, months_between, year, month,\n",
    "    round, log, sqrt, abs as spark_abs,\n",
    "    lit, coalesce, first, last, to_date, to_timestamp, trim\n",
    ")\n",
    "\n",
    "# 在Jupyter中创建SparkSession\n",
    "\n",
    "# 如果还没有创建SparkSession，则创建一个\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FeatureEngineering\") \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.sql.execution.arrow.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.network.timeout\", \"600s\") \\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"300s\") \\\n",
    "    .config(\"spark.rpc.numRetries\", \"10\") \\\n",
    "    .config(\"spark.rpc.retry.wait\", \"1s\") \\\n",
    "    .config(\"spark.shuffle.io.retryWait\", \"10s\") \\\n",
    "    .config(\"spark.shuffle.io.maxRetries\", \"5\") \\\n",
    "    .config(\"spark.executor.maxFailures\", \"5\") \\\n",
    "    .config(\"spark.task.maxFailures\", \"5\") \\\n",
    "    .config(\"spark.hadoop.dfs.permissions.enabled\", \"false\") \\\n",
    "    .config(\"spark.hadoop.fs.permissions.umask-mode\", \"000\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(f\"✓ Spark Session 创建成功\")\n",
    "print(f\"  Spark版本: {spark.version}\")\n",
    "print(f\"  Master: local[2]\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Spark Session 创建成功\n",
      "  Spark版本: 3.5.7\n",
      "  Master: local[2]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 步骤0: 加载数据源"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T02:48:38.769318Z",
     "start_time": "2025-12-08T02:48:34.756472Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 获取项目根目录 - 从test/spark目录向上找到项目根\n",
    "project_root = Path.cwd()\n",
    "while project_root.name != \"CASE-customer-group\" and project_root.parent != project_root:\n",
    "    project_root = project_root.parent\n",
    "\n",
    "# 数据文件路径 - 在项目根目录的output文件夹中\n",
    "# 这里假设已经运行过数据清洗脚本\n",
    "cleaned_base_path = str(project_root / \"output\" / \"cleaned_customer_base.csv\")\n",
    "cleaned_behavior_path = str(project_root / \"output\" / \"cleaned_customer_behavior.csv\")\n",
    "\n",
    "print(f\"数据目录: {project_root}\")\n",
    "print(f\"清洗后客户基本信息: {cleaned_base_path}\")\n",
    "print(f\"清洗后客户行为资产: {cleaned_behavior_path}\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    df_customer_base = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .csv(cleaned_base_path)\n",
    "\n",
    "    df_customer_behavior = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .csv(cleaned_behavior_path)\n",
    "\n",
    "    logger.info(f\"✓ 数据加载完成\")\n",
    "    logger.info(f\"  客户基本信息行数: {df_customer_base.count()}\")\n",
    "    logger.info(f\"  客户行为资产行数: {df_customer_behavior.count()}\")\n",
    "    \n",
    "    print(f\"✓ 数据加载完成\")\n",
    "    print(f\"  客户基本信息行数: {df_customer_base.count()}\")\n",
    "    print(f\"  客户行为资产行数: {df_customer_behavior.count()}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"加载数据失败: {str(e)}\")\n",
    "    print(f\"⚠ 数据加载失败: {str(e)}\")\n",
    "    print(f\"  请确保已运行数据清洗脚本 (test_spark_cleansing.ipynb)\")\n",
    "    raise"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据目录: C:\\Users\\hy120\\Downloads\\zhihullm\\CASE-customer-group\n",
      "清洗后客户基本信息: C:\\Users\\hy120\\Downloads\\zhihullm\\CASE-customer-group\\output\\cleaned_customer_base.csv\n",
      "清洗后客户行为资产: C:\\Users\\hy120\\Downloads\\zhihullm\\CASE-customer-group\\output\\cleaned_customer_behavior.csv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:✓ 数据加载完成\n",
      "INFO:__main__:  客户基本信息行数: 10000\n",
      "INFO:__main__:  客户行为资产行数: 120000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 数据加载完成\n",
      "  客户基本信息行数: 10000\n",
      "  客户行为资产行数: 120000\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 步骤1: 配置参数"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 配置参数（可根据需要修改）\nargs = {\n    'JOB_NAME': 'feature_engineering',\n    'INPUT_DATABASE': 'customer_cleaned_db',\n    'INPUT_TABLE_BASE': 'cleaned_customer_base',\n    'INPUT_TABLE_BEHAVIOR': 'cleaned_customer_behavior',\n    'OUTPUT_BUCKET': str(project_root / 'output'),\n    'OUTPUT_PATH': 'customer_features'\n}\n\n# 计算输出路径\noutput_path = f\"{args['OUTPUT_BUCKET']}/{args['OUTPUT_PATH']}\"\n\nlogger.info(f\"开始执行 {args['JOB_NAME']} 任务\")\nprint(f\"配置参数:\")\nprint(f\"  JOB_NAME: {args['JOB_NAME']}\")\nprint(f\"  OUTPUT_PATH: {output_path}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 步骤2: 基础特征构建"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T02:49:08.667116Z",
     "start_time": "2025-12-08T02:49:08.200109Z"
    }
   },
   "source": "logger.info(\"步骤2: 构建基础特征...\")\n\n# 2.1 人口统计特征\ndf_features = df_customer_base.select(\n    col(\"customer_id\"),\n    col(\"name\"),\n    col(\"age\"),\n    col(\"gender\"),\n    col(\"occupation_type\"),\n    col(\"monthly_income\"),\n    col(\"marriage_status\"),\n    col(\"city_level\"),\n    col(\"lifecycle_stage\"),\n    col(\"open_account_date\"),\n    col(\"branch_name\")\n)\n\n# 2.2 计算开户周期（天数）\n# 假设当前日期为最新的stat_month对应的月底\nreference_date = spark.createDataFrame(\n    [{\"ref_date\": datetime(2025, 6, 30)}]\n).select(\"ref_date\")\n\ndf_features = df_features.crossJoin(reference_date).select(\n    col(\"customer_id\"),\n    col(\"name\"),\n    col(\"age\"),\n    col(\"gender\"),\n    col(\"occupation_type\"),\n    col(\"monthly_income\"),\n    col(\"marriage_status\"),\n    col(\"city_level\"),\n    col(\"lifecycle_stage\"),\n    col(\"open_account_date\"),\n    datediff(col(\"ref_date\"), col(\"open_account_date\")).alias(\"days_as_customer\"),\n    months_between(col(\"ref_date\"), col(\"open_account_date\")).alias(\"months_as_customer\")\n)\n\n# 2.3 添加基础评分特征（基于人口统计）\ndf_features = df_features \\\n    .withColumn(\"income_score\",\n                when(col(\"monthly_income\") >= 50000, 100)\n                .when(col(\"monthly_income\") >= 30000, 75)\n                .when(col(\"monthly_income\") >= 15000, 50)\n                .otherwise(25)) \\\n    .withColumn(\"age_group\",\n                when(col(\"age\") < 30, \"18-30\")\n                .when(col(\"age\") < 40, \"30-40\")\n                .when(col(\"age\") < 50, \"40-50\")\n                .when(col(\"age\") < 60, \"50-60\")\n                .otherwise(\"60+\")) \\\n    .withColumn(\"lifecycle_score\",\n                when(col(\"lifecycle_stage\") == \"价值客户\", 100)\n                .when(col(\"lifecycle_stage\") == \"忠诚客户\", 85)\n                .when(col(\"lifecycle_stage\") == \"成熟客户\", 70)\n                .when(col(\"lifecycle_stage\") == \"成长客户\", 55)\n                .when(col(\"lifecycle_stage\") == \"新客户\", 30)\n                .otherwise(0))\n\nlogger.info(\"✓ 基础特征构建完成\")\nprint(f\"✓ 基础特征列数: {len(df_features.columns)}\")",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:步骤2: 构建基础特征...\n",
      "INFO:__main__:✓ 基础特征构建完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 基础特征列数: 15\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 步骤3: RFM 分析特征"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T02:52:58.641509Z",
     "start_time": "2025-12-08T02:52:57.516474Z"
    }
   },
   "source": "logger.info(\"步骤3: 生成RFM特征...\")\n\n# 准备行为数据，按客户汇总最新数据\ndf_behavior_latest = df_customer_behavior \\\n    .withColumn(\"rn\", row_number().over(\n        Window.partitionBy(\"customer_id\").orderBy(col(\"stat_month\").desc())\n    )) \\\n    .filter(col(\"rn\") == 1) \\\n    .select(\n        col(\"customer_id\"),\n        col(\"stat_month\").alias(\"last_contact_month\"),\n        col(\"last_app_login_time\"),\n        col(\"last_contact_time\"),\n        col(\"total_assets\"),\n        col(\"credit_card_monthly_expense\"),\n        col(\"investment_monthly_count\"),\n        col(\"app_login_count\"),\n        col(\"contact_result\"),\n        col(\"deposit_balance\"),\n        col(\"financial_balance\"),\n        col(\"fund_balance\"),\n        col(\"insurance_balance\"),\n        col(\"deposit_flag\"),\n        col(\"financial_flag\"),\n        col(\"fund_flag\"),\n        col(\"insurance_flag\")\n    )\n\n# 转换last_contact_time为日期，计算Recency\ndf_behavior_latest = df_behavior_latest \\\n    .withColumn(\"last_contact_date\",\n                when(col(\"last_contact_time\").isNotNull(),\n                     col(\"last_contact_time\").cast(\"date\"))\n                .otherwise(None)) \\\n    .withColumn(\"recency_days\",\n                when(col(\"last_contact_date\").isNotNull(),\n                     datediff(lit(datetime(2025, 6, 30)), col(\"last_contact_date\")))\n                .otherwise(999))  # 从未联系的设为999天\n\n# 频率 (Frequency): 使用app_login_count作为代理\ndf_behavior_latest = df_behavior_latest \\\n    .withColumn(\"frequency_score\",\n                when(col(\"app_login_count\") >= 10, 100)\n                .when(col(\"app_login_count\") >= 5, 75)\n                .when(col(\"app_login_count\") >= 2, 50)\n                .otherwise(25))\n\n# 金额 (Monetary): 基于total_assets\n# 计算所有客户资产的分位数用于评分\nasset_percentiles = df_behavior_latest.selectExpr(\n    \"percentile_approx(total_assets, 0.25) as p25\",\n    \"percentile_approx(total_assets, 0.50) as p50\",\n    \"percentile_approx(total_assets, 0.75) as p75\"\n).collect()[0]\n\ndf_behavior_latest = df_behavior_latest \\\n    .withColumn(\"monetary_score\",\n                when(col(\"total_assets\") >= asset_percentiles['p75'], 100)\n                .when(col(\"total_assets\") >= asset_percentiles['p50'], 75)\n                .when(col(\"total_assets\") >= asset_percentiles['p25'], 50)\n                .otherwise(25))\n\n# 综合RFM评分\ndf_behavior_latest = df_behavior_latest \\\n    .withColumn(\"rfm_score\",\n                round((col(\"frequency_score\") * 0.4 +\n                       col(\"monetary_score\") * 0.4 +\n                       (100 - col(\"recency_days\")/999*100) * 0.2), 2))\n\nlogger.info(\"✓ RFM特征生成完成\")\nprint(f\"✓ RFM特征生成完成\")",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:步骤3: 生成RFM特征...\n",
      "INFO:__main__:✓ RFM特征生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RFM特征生成完成\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 步骤4: 行为活跃度和资产特征"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T02:53:06.298194Z",
     "start_time": "2025-12-08T02:53:06.181700Z"
    }
   },
   "source": "logger.info(\"步骤4: 生成行为活跃度和资产特征...\")\n\n# 4.1 行为活跃度特征\ndf_behavior_latest = df_behavior_latest \\\n    .withColumn(\"engagement_score\",\n                round((col(\"app_login_count\") * 10 +\n                       col(\"investment_monthly_count\") * 20) / 30, 2)) \\\n    .withColumn(\"is_active_app\",\n                when(col(\"app_login_count\") >= 3, 1).otherwise(0)) \\\n    .withColumn(\"is_active_investor\",\n                when(col(\"investment_monthly_count\") >= 1, 1).otherwise(0)) \\\n    .withColumn(\"is_active_consumer\",\n                when(col(\"credit_card_monthly_expense\") > 0, 1).otherwise(0)) \\\n    .withColumn(\"activity_type\",\n                when((col(\"is_active_app\") == 1) & (col(\"is_active_investor\") == 1), \"多元活跃\")\n                .when(col(\"is_active_investor\") == 1, \"投资活跃\")\n                .when(col(\"is_active_app\") == 1, \"应用活跃\")\n                .when(col(\"is_active_consumer\") == 1, \"消费活跃\")\n                .otherwise(\"低活跃\"))\n\n# 4.2 资产特征\ndf_behavior_latest = df_behavior_latest \\\n    .withColumn(\"asset_concentration\",\n                round(((col(\"deposit_balance\") ** 2 +\n                        col(\"financial_balance\") ** 2 +\n                        col(\"fund_balance\") ** 2 +\n                        col(\"insurance_balance\") ** 2) /\n                       (col(\"total_assets\") ** 2)), 4)) \\\n    .withColumn(\"investment_product_diversity\",\n                col(\"deposit_flag\") + col(\"financial_flag\") +\n                col(\"fund_flag\") + col(\"insurance_flag\")) \\\n    .withColumn(\"diversification_score\",\n                when(col(\"investment_product_diversity\") == 4, 100)\n                .when(col(\"investment_product_diversity\") == 3, 75)\n                .when(col(\"investment_product_diversity\") == 2, 50)\n                .when(col(\"investment_product_diversity\") == 1, 25)\n                .otherwise(0))\n\nlogger.info(\"✓ 行为活跃度和资产特征生成完成\")\nprint(f\"✓ 行为活跃度和资产特征生成完成\")",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:步骤4: 生成行为活跃度和资产特征...\n",
      "INFO:__main__:✓ 行为活跃度和资产特征生成完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 行为活跃度和资产特征生成完成\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 步骤5: 客户价值评分和分层"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T02:53:09.094306Z",
     "start_time": "2025-12-08T02:53:09.049554Z"
    }
   },
   "source": "logger.info(\"步骤5: 计算客户价值评分和分层...\")\n\n# 计算客户价值评分和分层\ndf_behavior_latest = df_behavior_latest \\\n    .withColumn(\"customer_value_score\",\n                round((col(\"rfm_score\") * 0.4 +\n                       col(\"engagement_score\") * 0.3 +\n                       col(\"diversification_score\") * 0.3), 2)) \\\n    .withColumn(\"customer_tier\",\n                when(col(\"customer_value_score\") >= 80, \"VIP高价值\")\n                .when(col(\"customer_value_score\") >= 60, \"核心客户\")\n                .when(col(\"customer_value_score\") >= 40, \"重点培育\")\n                .otherwise(\"低价值\"))\n\nlogger.info(\"✓ 客户价值评分和分层完成\")\nprint(f\"✓ 客户价值评分和分层完成\")",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:步骤5: 计算客户价值评分和分层...\n",
      "INFO:__main__:✓ 客户价值评分和分层完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 客户价值评分和分层完成\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 步骤6: 交叉销售和风险评分"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T02:53:11.446342Z",
     "start_time": "2025-12-08T02:53:11.339702Z"
    }
   },
   "source": "logger.info(\"步骤6: 生成交叉销售指数和风险评分...\")\n\n# 6.1 产品交叉销售机会评分\ndf_behavior_latest = df_behavior_latest \\\n    .withColumn(\"financial_upgrade_score\",\n                when((col(\"deposit_flag\") == 1) & (col(\"financial_flag\") == 0),\n                     round(col(\"engagement_score\") * 1.2, 2))\n                .otherwise(0)) \\\n    .withColumn(\"fund_upgrade_score\",\n                when((col(\"financial_flag\") == 1) & (col(\"fund_flag\") == 0),\n                     round(col(\"engagement_score\") * 0.9, 2))\n                .otherwise(0)) \\\n    .withColumn(\"insurance_upgrade_score\",\n                when(col(\"insurance_flag\") == 0,\n                     round(col(\"rfm_score\") * col(\"engagement_score\") / 100, 2))\n                .otherwise(0)) \\\n    .withColumn(\"credit_card_upgrade_score\",\n                when(col(\"credit_card_monthly_expense\") > 0,\n                     50 + round(col(\"engagement_score\") * 0.5, 2))\n                .otherwise(30))\n\n# 6.2 风险评分\ndf_behavior_latest = df_behavior_latest \\\n    .withColumn(\"churn_risk_score\",\n                when(col(\"recency_days\") > 180, 80)  # 6个月未联系\n                .when(col(\"recency_days\") > 90, 60)   # 3个月未联系\n                .when(col(\"recency_days\") > 30, 40)   # 1个月未联系\n                .when(col(\"contact_result\") == \"拒绝\", 50)\n                .otherwise(20)) \\\n    .withColumn(\"is_at_risk\",\n                when(col(\"churn_risk_score\") >= 60, 1).otherwise(0))\n\nlogger.info(\"✓ 交叉销售和风险评分完成\")\nprint(f\"✓ 交叉销售和风险评分完成\")",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:步骤6: 生成交叉销售指数和风险评分...\n",
      "INFO:__main__:✓ 交叉销售和风险评分完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 交叉销售和风险评分完成\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 步骤7: 合并所有特征"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T02:53:14.877923Z",
     "start_time": "2025-12-08T02:53:14.787588Z"
    }
   },
   "source": "logger.info(\"步骤7: 合并所有特征...\")\n\ndf_final_features = df_features \\\n    .join(df_behavior_latest, on=\"customer_id\", how=\"left\") \\\n    .select(\n        # 基础信息\n        col(\"customer_id\"),\n        col(\"name\"),\n        col(\"age\"),\n        col(\"age_group\"),\n        col(\"gender\"),\n        col(\"occupation_type\"),\n        col(\"monthly_income\"),\n        col(\"marriage_status\"),\n        col(\"city_level\"),\n        col(\"lifecycle_stage\"),\n\n        # 客户周期特征\n        col(\"days_as_customer\"),\n        col(\"months_as_customer\"),\n\n        # 资产特征\n        col(\"total_assets\"),\n        col(\"deposit_balance\"),\n        col(\"financial_balance\"),\n        col(\"fund_balance\"),\n        col(\"insurance_balance\"),\n        col(\"asset_concentration\"),\n        col(\"investment_product_diversity\"),\n\n        # 行为特征\n        col(\"app_login_count\"),\n        col(\"credit_card_monthly_expense\"),\n        col(\"investment_monthly_count\"),\n        col(\"activity_type\"),\n        col(\"is_active_app\"),\n        col(\"is_active_investor\"),\n        col(\"is_active_consumer\"),\n\n        # RFM评分\n        col(\"recency_days\"),\n        col(\"frequency_score\"),\n        col(\"monetary_score\"),\n        col(\"rfm_score\"),\n\n        # 活跃度评分\n        col(\"engagement_score\"),\n\n        # 多维度评分\n        col(\"income_score\"),\n        col(\"lifecycle_score\"),\n        col(\"diversification_score\"),\n\n        # 客户价值评分\n        col(\"customer_value_score\"),\n        col(\"customer_tier\"),\n\n        # 交叉销售机会\n        col(\"financial_upgrade_score\"),\n        col(\"fund_upgrade_score\"),\n        col(\"insurance_upgrade_score\"),\n        col(\"credit_card_upgrade_score\"),\n\n        # 风险评分\n        col(\"churn_risk_score\"),\n        col(\"is_at_risk\"),\n\n        # 最后更新时间\n        col(\"last_contact_date\"),\n        col(\"last_app_login_time\")\n    )\n\nlogger.info(\"✓ 所有特征合并完成\")\nprint(f\"✓ 所有特征合并完成\")\nprint(f\"  最终特征列数: {len(df_final_features.columns)}\")",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:步骤7: 合并所有特征...\n",
      "INFO:__main__:✓ 所有特征合并完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 所有特征合并完成\n",
      "  最终特征列数: 44\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 步骤8: 特征统计和验证"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T02:53:26.894800Z",
     "start_time": "2025-12-08T02:53:20.072736Z"
    }
   },
   "source": "logger.info(\"步骤8: 特征统计...\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"特征统计和验证\")\nprint(\"=\"*80)\n\nprint(f\"\\n最终特征表行数: {df_final_features.count()}\")\nprint(f\"特征列数: {len(df_final_features.columns)}\")\n\n# 统计各客户分层\nlogger.info(\"客户分层分布:\")\nprint(\"\\n客户分层分布:\")\ntry:\n    tier_stats = df_final_features.groupBy(\"customer_tier\").count().orderBy(\"count\", ascending=False).collect()\n    for row in tier_stats:\n        print(f\"  {row['customer_tier']}: {row['count']} 人\")\n        logger.info(f\"  {row['customer_tier']}: {row['count']} 人\")\nexcept Exception as e:\n    logger.warning(f\"客户分层统计失败（跳过）: {str(e)}\")\n    print(f\"  (统计失败)\")\n\n# 统计活动类型分布\nlogger.info(\"活跃类型分布:\")\nprint(\"\\n活跃类型分布:\")\ntry:\n    activity_stats = df_final_features.groupBy(\"activity_type\").count().orderBy(\"count\", ascending=False).collect()\n    for row in activity_stats:\n        print(f\"  {row['activity_type']}: {row['count']} 人\")\n        logger.info(f\"  {row['activity_type']}: {row['count']} 人\")\nexcept Exception as e:\n    logger.warning(f\"活动类型统计失败（跳过）: {str(e)}\")\n    print(f\"  (统计失败)\")\n\n# 统计风险客户\nprint(\"\\n风险客户统计:\")\ntry:\n    at_risk_count = df_final_features.filter(col(\"is_at_risk\") == 1).count()\n    print(f\"  处于风险的客户: {at_risk_count} 人\")\n    logger.info(f\"  处于风险的客户: {at_risk_count} 人\")\nexcept Exception as e:\n    logger.warning(f\"风险统计失败（跳过）: {str(e)}\")\n\nprint(\"\\n\" + \"=\"*80)",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:步骤8: 特征统计...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "特征统计和验证\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:客户分层分布:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "最终特征表行数: 10000\n",
      "特征列数: 44\n",
      "\n",
      "客户分层分布:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:  低价值: 5429 人\n",
      "INFO:__main__:  重点培育: 4277 人\n",
      "INFO:__main__:  核心客户: 294 人\n",
      "INFO:__main__:活跃类型分布:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  低价值: 5429 人\n",
      "  重点培育: 4277 人\n",
      "  核心客户: 294 人\n",
      "\n",
      "活跃类型分布:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:  应用活跃: 5087 人\n",
      "INFO:__main__:  多元活跃: 3222 人\n",
      "INFO:__main__:  消费活跃: 865 人\n",
      "INFO:__main__:  投资活跃: 486 人\n",
      "INFO:__main__:  低活跃: 340 人\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  应用活跃: 5087 人\n",
      "  多元活跃: 3222 人\n",
      "  消费活跃: 865 人\n",
      "  投资活跃: 486 人\n",
      "  低活跃: 340 人\n",
      "\n",
      "风险客户统计:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:  处于风险的客户: 1906 人\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  处于风险的客户: 1906 人\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 步骤9: 输出特征表"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "logger.info(\"步骤9: 输出特征表...\")\n\n# 创建output目录\noutput_dir = Path(output_path)\noutput_dir.mkdir(parents=True, exist_ok=True)\n\ntry:\n    # 输出特征表为CSV\n    df_final_features.coalesce(1) \\\n        .write.mode(\"overwrite\") \\\n        .option(\"header\", \"true\") \\\n        .csv(output_path)\n    \n    logger.info(f\"特征表已输出到: {output_path}\")\n    print(f\"\\n✓ 特征表已输出\")\n    print(f\"  路径: {output_path}\")\n    print(f\"  行数: {df_final_features.count()}\")\n    print(f\"  列数: {len(df_final_features.columns)}\")\nexcept Exception as e:\n    logger.error(f\"输出特征表失败: {str(e)}\")\n    print(f\"⚠ 输出特征表失败: {str(e)}\")\n    raise"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 步骤10: 预览结果"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n【特征工程结果预览 - 核心特征前5行】\\n\")\n\n# 显示核心特征\ndf_final_features.select(\n    \"customer_id\",\n    \"name\",\n    \"age\",\n    \"monthly_income\",\n    \"customer_tier\",\n    \"customer_value_score\",\n    \"rfm_score\",\n    \"engagement_score\",\n    \"activity_type\",\n    \"churn_risk_score\"\n).show(5, truncate=False)\n\nprint(\"\\n【客户分层分布】\\n\")\ndf_final_features.groupBy(\"customer_tier\").count().orderBy(\"count\", ascending=False).show(truncate=False)\n\nprint(\"\\n【活跃类型分布】\\n\")\ndf_final_features.groupBy(\"activity_type\").count().orderBy(\"count\", ascending=False).show(truncate=False)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 完成任务"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "logger.info(f\"{args['JOB_NAME']} 任务完成！\")\nprint(\"\\n\" + \"=\"*80)\nprint(f\"✓ {args['JOB_NAME']} 任务完成！\")\nprint(\"=\"*80)\nprint(\"\\n汇总:\")\nprint(f\"  输入客户数: {df_customer_base.count()}\")\nprint(f\"  输出特征数: {df_final_features.count()}\")\nprint(f\"  生成特征列数: {len(df_final_features.columns)}\")\nprint(f\"  输出路径: {output_path}\")\nprint(\"\\n\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 清理资源"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 停止Spark Session\nspark.stop()\nlogger.info(\"Spark Session 已停止\")\nprint(\"✓ Spark Session 已停止\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完成任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"{args['JOB_NAME']} 任务完成！\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
