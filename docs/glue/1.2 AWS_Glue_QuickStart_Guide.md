# AWS Glue å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸ“‹ ç›®å½•

1. [å‰ç½®æ¡ä»¶](#å‰ç½®æ¡ä»¶)
2. [5åˆ†é’Ÿå¿«é€Ÿéƒ¨ç½²](#5åˆ†é’Ÿå¿«é€Ÿéƒ¨ç½²)
3. [è¯¦ç»†æ­¥éª¤](#è¯¦ç»†æ­¥éª¤)
4. [éªŒè¯éƒ¨ç½²](#éªŒè¯éƒ¨ç½²)
5. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
6. [ç›‘æ§å’Œå‘Šè­¦](#ç›‘æ§å’Œå‘Šè­¦)
7. [æˆæœ¬ä¼˜åŒ–](#æˆæœ¬ä¼˜åŒ–)

---

## å‰ç½®æ¡ä»¶

### å¿…éœ€è½¯ä»¶
- AWS CLI v2.x æˆ–ä»¥ä¸Š
- Bash shell (Linux/Mac) æˆ– PowerShell (Windows)
- Python 3.7+ (å¯é€‰ï¼Œç”¨äºæœ¬åœ°æµ‹è¯•)

### AWSè´¦æˆ·è¦æ±‚
- æœ‰æ•ˆçš„AWSè´¦æˆ·
- å¿…è¦çš„IAMæƒé™:
  - `glue:*` (AWS Glue)
  - `s3:*` (S3 è®¿é—®)
  - `iam:CreateRole`, `iam:PutRolePolicy`, `iam:GetRole`
  - `logs:*` (CloudWatch Logs)
  - `cloudwatch:PutMetricData`

### ç¯å¢ƒå˜é‡è®¾ç½®

```bash
# è®¾ç½®é»˜è®¤AWSåŒºåŸŸ
export AWS_REGION=us-east-1

# è®¾ç½®AWSå‡­è¯ (å¦‚æœæœªé…ç½®)
export AWS_ACCESS_KEY_ID=your-access-key
export AWS_SECRET_ACCESS_KEY=your-secret-key

# è®¾ç½®S3æ¡¶åç§°
export CUSTOMER_BUCKET=your-customer-data-bucket
```

---

## 5åˆ†é’Ÿå¿«é€Ÿéƒ¨ç½²

### Step 1: å…‹éš†æˆ–ä¸‹è½½è„šæœ¬

```bash
# åˆ›å»ºå·¥ä½œç›®å½•
mkdir -p aws-glue-setup && cd aws-glue-setup

# å¤åˆ¶æ‰€æœ‰Glueè„šæœ¬åˆ°å½“å‰ç›®å½•
cp -r glue_scripts/ .
```

### Step 2: ä¿®æ”¹é…ç½®æ–‡ä»¶

ç¼–è¾‘ `glue_scripts/deploy.sh`:

```bash
# ç¬¬10-12è¡Œï¼Œä¿®æ”¹ä»¥ä¸‹å˜é‡:
AWS_REGION="us-east-1"          # æ”¹ä¸ºä½ çš„åŒºåŸŸ
S3_BUCKET="your-bucket-name"    # æ”¹ä¸ºä½ çš„S3æ¡¶å
ROLE_NAME="GlueCustomerDataRole" # å¯é€‰ï¼Œæ”¹ä¸ºä½ çš„è§’è‰²å
```

### Step 3: è¿è¡Œéƒ¨ç½²è„šæœ¬

```bash
# ç»™è„šæœ¬æ‰§è¡Œæƒé™
chmod +x glue_scripts/deploy.sh

# æ‰§è¡Œéƒ¨ç½²è„šæœ¬
./glue_scripts/deploy.sh
```

éƒ¨ç½²è„šæœ¬ä¼šè‡ªåŠ¨åˆ›å»º:
- âœ… IAM è§’è‰²
- âœ… S3 æ¡¶å’Œç›®å½•
- âœ… Glue æ•°æ®åº“
- âœ… Glue Crawler
- âœ… Glue Jobs
- âœ… Glue Triggers

**é¢„è®¡æ—¶é—´**: 2-3 åˆ†é’Ÿ

### Step 4: ä¸Šä¼ æºæ•°æ®

```bash
# ä¸Šä¼ å®¢æˆ·åŸºæœ¬ä¿¡æ¯
aws s3 cp customer_base.csv s3://your-bucket-name/raw/customer_base/

# ä¸Šä¼ å®¢æˆ·è¡Œä¸ºèµ„äº§æ•°æ®
aws s3 cp customer_behavior_assets.csv s3://your-bucket-name/raw/customer_behavior_assets/
```

### Step 5: å¯åŠ¨æ•°æ®å¤„ç†

```bash
# å¯åŠ¨Crawler (è‡ªåŠ¨å‘ç°å…ƒæ•°æ®)
aws glue start-crawler --name customer-data-crawler

# ç­‰å¾…Crawlerå®Œæˆ (é€šå¸¸5-10åˆ†é’Ÿ)
# ç„¶åå¯åŠ¨æ•°æ®æ¸…æ´—Job
aws glue start-job-run \
  --job-name customer-data-cleansing \
  --arguments '{"--INPUT_DATABASE":"customer_raw_db","--INPUT_TABLE_BASE":"raw_customer_base","--INPUT_TABLE_BEHAVIOR":"raw_customer_behavior_assets"}'

# å¯åŠ¨ç‰¹å¾å·¥ç¨‹Job (Crawlerå®Œæˆå)
aws glue start-job-run \
  --job-name customer-feature-engineering
```

---

## è¯¦ç»†æ­¥éª¤

### è¯¦ç»†Step 1: éªŒè¯AWS CLI

```bash
# æ£€æŸ¥AWS CLIç‰ˆæœ¬
aws --version

# æ£€æŸ¥AWSå‡­è¯é…ç½®
aws sts get-caller-identity

# è¾“å‡ºåº”è¯¥æ˜¯:
# {
#     "UserId": "...",
#     "Account": "123456789",
#     "Arn": "arn:aws:iam::123456789:user/..."
# }
```

### è¯¦ç»†Step 2: åˆ›å»ºS3æ¡¶ (å¦‚æœä¸å­˜åœ¨)

```bash
# åˆ›å»ºS3æ¡¶
aws s3 mb s3://your-customer-data-bucket --region us-east-1

# å¯ç”¨ç‰ˆæœ¬æ§åˆ¶ (å¯é€‰)
aws s3api put-bucket-versioning \
  --bucket your-customer-data-bucket \
  --versioning-configuration Status=Enabled

# å¯ç”¨åŠ å¯† (å¯é€‰)
aws s3api put-bucket-encryption \
  --bucket your-customer-data-bucket \
  --server-side-encryption-configuration '{
    "Rules": [{
      "ApplyServerSideEncryptionByDefault": {
        "SSEAlgorithm": "AES256"
      }
    }]
  }'
```

### è¯¦ç»†Step 3: åˆ›å»ºIAMè§’è‰²

```bash
# åˆ›å»ºä¿¡ä»»ç­–ç•¥æ–‡ä»¶
cat > trust-policy.json << 'EOF'
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": "glue.amazonaws.com"
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
EOF

# åˆ›å»ºè§’è‰²
aws iam create-role \
  --role-name GlueCustomerDataRole \
  --assume-role-policy-document file://trust-policy.json

# é™„åŠ ç­–ç•¥
aws iam attach-role-policy \
  --role-name GlueCustomerDataRole \
  --policy-arn arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole
```

### è¯¦ç»†Step 4: åˆ›å»ºGlueæ•°æ®åº“

```bash
# åˆ›å»ºåŸå§‹æ•°æ®åº“
aws glue create-database \
  --database-input '{
    "Name": "customer_raw_db",
    "Description": "åŸå§‹å®¢æˆ·æ•°æ®"
  }'

# åˆ›å»ºæ¸…æ´—æ•°æ®åº“
aws glue create-database \
  --database-input '{
    "Name": "customer_cleaned_db",
    "Description": "æ¸…æ´—åçš„å®¢æˆ·æ•°æ®"
  }'

# åˆ›å»ºç‰¹å¾æ•°æ®åº“
aws glue create-database \
  --database-input '{
    "Name": "customer_feature_db",
    "Description": "å®¢æˆ·ç‰¹å¾æ•°æ®"
  }'

# åˆ—å‡ºæ‰€æœ‰æ•°æ®åº“
aws glue list-databases
```

### è¯¦ç»†Step 5: ä¸Šä¼ Glueè„šæœ¬

```bash
# åˆ›å»ºscriptsç›®å½•
aws s3api put-object \
  --bucket your-customer-data-bucket \
  --key scripts/

# ä¸Šä¼ æ•°æ®æ¸…æ´—è„šæœ¬
aws s3 cp glue_scripts/1_data_cleansing.py \
  s3://your-customer-data-bucket/scripts/

# ä¸Šä¼ ç‰¹å¾å·¥ç¨‹è„šæœ¬
aws s3 cp glue_scripts/2_feature_engineering.py \
  s3://your-customer-data-bucket/scripts/

# éªŒè¯ä¸Šä¼ 
aws s3 ls s3://your-customer-data-bucket/scripts/
```

### è¯¦ç»†Step 6: åˆ›å»ºGlue Crawler

```bash
ROLE_ARN="arn:aws:iam::$(aws sts get-caller-identity --query Account --output text):role/GlueCustomerDataRole"

aws glue create-crawler \
  --name customer-data-crawler \
  --role "$ROLE_ARN" \
  --database-name customer_raw_db \
  --targets "S3Targets=[{Path=s3://your-customer-data-bucket/raw/}]" \
  --schedule-expression 'cron(0 0 * * ? *)' \
  --table-prefix raw_ \
  --description "è‡ªåŠ¨å‘ç°å®¢æˆ·æ•°æ®"

# éªŒè¯Crawleråˆ›å»º
aws glue get-crawler --name customer-data-crawler
```

### è¯¦ç»†Step 7: åˆ›å»ºGlue Jobs

```bash
ROLE_ARN="arn:aws:iam::$(aws sts get-caller-identity --query Account --output text):role/GlueCustomerDataRole"

# åˆ›å»ºæ•°æ®æ¸…æ´—Job
aws glue create-job \
  --name customer-data-cleansing \
  --role "$ROLE_ARN" \
  --command "Name=glueetl,ScriptLocation=s3://your-customer-data-bucket/scripts/1_data_cleansing.py" \
  --max-capacity 2 \
  --glue-version 4.0 \
  --timeout 30 \
  --description "æ¸…æ´—å’Œæ ‡å‡†åŒ–å®¢æˆ·æ•°æ®"

# åˆ›å»ºç‰¹å¾å·¥ç¨‹Job
aws glue create-job \
  --name customer-feature-engineering \
  --role "$ROLE_ARN" \
  --command "Name=glueetl,ScriptLocation=s3://your-customer-data-bucket/scripts/2_feature_engineering.py" \
  --max-capacity 2 \
  --glue-version 4.0 \
  --timeout 30 \
  --description "ç”Ÿæˆå®¢æˆ·ç‰¹å¾"

# åˆ—å‡ºæ‰€æœ‰Jobs
aws glue list-jobs
```

---

## éªŒè¯éƒ¨ç½²

### æ£€æŸ¥æ¸…å•

```bash
# 1. æ£€æŸ¥IAMè§’è‰²
aws iam get-role --role-name GlueCustomerDataRole

# 2. æ£€æŸ¥S3æ¡¶
aws s3 ls s3://your-customer-data-bucket/

# 3. æ£€æŸ¥Glueæ•°æ®åº“
aws glue list-databases

# 4. æ£€æŸ¥Glue Crawler
aws glue list-crawlers

# 5. æ£€æŸ¥Glue Jobs
aws glue list-jobs
```

### è¿è¡Œæµ‹è¯•

```bash
# å¯åŠ¨Crawler
aws glue start-crawler --name customer-data-crawler

# æŸ¥è¯¢CrawlerçŠ¶æ€
aws glue get-crawler --name customer-data-crawler --query 'Crawler.State' --output text

# å½“çŠ¶æ€ä¸ºREADYæ—¶ï¼ŒæŸ¥çœ‹çˆ¬å–åˆ°çš„è¡¨
aws glue get-tables --database-name customer_raw_db

# è¿è¡Œæ•°æ®æ¸…æ´—Job
JOB_RUN_ID=$(aws glue start-job-run \
  --job-name customer-data-cleansing \
  --arguments '{
    "--INPUT_DATABASE": "customer_raw_db",
    "--INPUT_TABLE_BASE": "raw_customer_base",
    "--INPUT_TABLE_BEHAVIOR": "raw_customer_behavior_assets",
    "--OUTPUT_BUCKET": "s3://your-customer-data-bucket/cleaned",
    "--OUTPUT_PATH_BASE": "customer_base",
    "--OUTPUT_PATH_BEHAVIOR": "customer_behavior"
  }' \
  --query 'JobRunId' \
  --output text)

echo "Job Run ID: $JOB_RUN_ID"

# æŸ¥è¯¢Jobæ‰§è¡ŒçŠ¶æ€
aws glue get-job-run \
  --job-name customer-data-cleansing \
  --run-id "$JOB_RUN_ID"
```

### æŸ¥çœ‹è¾“å‡ºç»“æœ

```bash
# æŸ¥çœ‹æ¸…æ´—åçš„æ•°æ®
aws s3 ls s3://your-customer-data-bucket/cleaned/customer_base/
aws s3 ls s3://your-customer-data-bucket/cleaned/customer_behavior/

# ä½¿ç”¨AthenaæŸ¥è¯¢
# SELECT COUNT(*) FROM customer_raw_db.raw_customer_base;
# SELECT * FROM customer_cleaned_db.cleaned_customer_base LIMIT 10;
```

---

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•ä¿®æ”¹Jobå‚æ•°?

```bash
# æ›´æ–°Jobå®šä¹‰
aws glue update-job \
  --name customer-data-cleansing \
  --role arn:aws:iam::123456789:role/GlueCustomerDataRole \
  --command "Name=glueetl,ScriptLocation=s3://bucket/scripts/1_data_cleansing.py" \
  --max-capacity 4  # å¢åŠ è®¡ç®—èµ„æº
```

### Q2: å¦‚ä½•æŸ¥çœ‹Jobæ—¥å¿—?

```bash
# æŸ¥çœ‹æœ€è¿‘çš„Jobè¿è¡Œ
aws glue get-job-runs \
  --job-name customer-data-cleansing \
  --max-results 5

# æŸ¥çœ‹Jobè¿è¡Œçš„è¯¦ç»†æ—¥å¿—
# æ—¥å¿—ä½äº: CloudWatch Logs -> /aws-glue/jobs/customer-data-cleansing

# ä½¿ç”¨AWS CLIæŸ¥è¯¢æ—¥å¿—
aws logs describe-log-streams \
  --log-group-name /aws-glue/jobs/customer-data-cleansing

# æŸ¥çœ‹å…·ä½“æ—¥å¿—å†…å®¹
aws logs get-log-events \
  --log-group-name /aws-glue/jobs/customer-data-cleansing \
  --log-stream-name job_run_id \
  --query 'events[].message' \
  --output text
```

### Q3: å¦‚ä½•è°ƒè¯•è„šæœ¬é”™è¯¯?

```bash
# 1. æŸ¥çœ‹Jobé”™è¯¯ä¿¡æ¯
aws glue get-job-run \
  --job-name customer-data-cleansing \
  --run-id job_run_id \
  --query 'JobRun.ErrorMessage'

# 2. æŸ¥çœ‹CloudWatchæ—¥å¿— (è¯¦ç»†)
# è®¿é—®: AWS Console -> CloudWatch -> Logs -> /aws-glue/jobs/

# 3. æœ¬åœ°æµ‹è¯•è„šæœ¬
# åœ¨æœ¬åœ°ç¯å¢ƒä¸­ä½¿ç”¨Sparkè¿è¡Œè„šæœ¬è¿›è¡Œè°ƒè¯•
```

### Q4: å¦‚ä½•æŒ‰ç…§è®¡åˆ’è¿è¡ŒJob?

```bash
# åˆ›å»ºè§¦å‘å™¨ - æ¯å¤©2:00 AMè¿è¡Œ
aws glue create-trigger \
  --name daily-cleansing-trigger \
  --type SCHEDULED \
  --schedule 'cron(0 2 * * ? *)' \
  --actions "[{JobName=customer-data-cleansing}]"

# åˆ›å»ºè§¦å‘å™¨ - å½“æŸä¸ªJobå®Œæˆåå¯åŠ¨å¦ä¸€ä¸ªJob
aws glue create-trigger \
  --name feature-engineering-trigger \
  --type CONDITIONAL \
  --actions "[{JobName=customer-feature-engineering}]" \
  --predicate '{
    "Logical": "ANY",
    "Conditions": [{
      "LogicalOperator": "EQUALS",
      "JobName": "customer-data-cleansing",
      "State": "SUCCEEDED"
    }]
  }'
```

### Q5: å¦‚ä½•å¤„ç†æ•°æ®é‡å¤å¤„ç†?

```bash
# å¹‚ç­‰æ€§è®¾è®¡ - ä½¿ç”¨å¹´æœˆåˆ†åŒº
# æ¸…æ´è„šæœ¬åº”è¯¥æ£€æŸ¥ç›®æ ‡è·¯å¾„å¹¶è¦†ç›–:
# df.write.mode("overwrite").parquet(output_path)

# æŸ¥çœ‹åˆ†åŒºä¿¡æ¯
aws glue get-partitions \
  --database-name customer_cleaned_db \
  --table-name cleaned_customer_base
```

---

## ç›‘æ§å’Œå‘Šè­¦

### CloudWatchæŒ‡æ ‡

```bash
# åˆ›å»ºè‡ªå®šä¹‰æŒ‡æ ‡å‘Šè­¦
aws cloudwatch put-metric-alarm \
  --alarm-name glue-job-failure \
  --alarm-description "Glue Job å¤±è´¥å‘Šè­¦" \
  --metric-name glue_job_failure \
  --namespace AWS/Glue \
  --statistic Sum \
  --period 300 \
  --threshold 1 \
  --comparison-operator GreaterThanOrEqualToThreshold \
  --evaluation-periods 1
```

### SNSé€šçŸ¥

```bash
# åˆ›å»ºSNSä¸»é¢˜
aws sns create-topic --name glue-alerts

# è®¢é˜…é‚®ä»¶é€šçŸ¥
aws sns subscribe \
  --topic-arn arn:aws:sns:us-east-1:123456789:glue-alerts \
  --protocol email \
  --notification-endpoint your-email@example.com
```

---

## æˆæœ¬ä¼˜åŒ–

### 1. ä½¿ç”¨Spark Flex Instances

```bash
# åˆ›å»ºæ›´ç»æµçš„Job (G.2X)
aws glue create-job \
  --name customer-data-cleansing \
  --worker-type G.2X \
  --number-of-workers 2
  # G.1X: $0.44/å°æ—¶
  # G.2X: $0.88/å°æ—¶ (æ›´å¿«ï¼Œä½†è´µä¸€å€)
```

### 2. ä¼˜åŒ–Jobé…ç½®

```bash
# é™ä½å¹¶å‘åº¦ï¼ˆå¦‚æœä¸éœ€è¦å¹¶è¡Œï¼‰
aws glue update-job \
  --name customer-data-cleansing \
  --max-capacity 1  # ä»2é™åˆ°1

# æˆ–ä½¿ç”¨G.1Xå•ä¸ªworker
--worker-type G.1X
--number-of-workers 1
```

### 3. æ•°æ®åˆ†åŒº

åœ¨è„šæœ¬ä¸­æ·»åŠ åˆ†åŒºå¤„ç†ï¼Œå‡å°‘æ•°æ®æ‰«æé‡

### 4. å®šæœŸæ¸…ç†æ•°æ®

```bash
# åˆ›å»ºS3ç”Ÿå‘½å‘¨æœŸç­–ç•¥ä»¥è‡ªåŠ¨åˆ é™¤æ—§æ•°æ®
aws s3api put-bucket-lifecycle-configuration \
  --bucket your-customer-data-bucket \
  --lifecycle-configuration '{
    "Rules": [{
      "Id": "DeleteOldRawData",
      "Filter": {"Prefix": "raw/"},
      "Expiration": {"Days": 90},
      "Status": "Enabled"
    }]
  }'
```

---

## åç»­æ­¥éª¤

1. âœ… éƒ¨ç½²å®Œæˆåï¼ŒæŸ¥çœ‹ EDA_Summary_Report.md äº†è§£æ•°æ®æ´å¯Ÿ
2. âœ… æ ¹æ®ä¸šåŠ¡éœ€æ±‚ï¼Œè‡ªå®šä¹‰åˆ†ç¾¤å’Œæ¨èé€»è¾‘
3. âœ… é›†æˆBIå·¥å…·ï¼ˆTableau, QuickSightï¼‰è¿›è¡Œå¯è§†åŒ–
4. âœ… è€ƒè™‘é›†æˆSageMakerè¿›è¡Œæœºå™¨å­¦ä¹ 

---

## æ”¯æŒå’Œæ–‡æ¡£

- AWS Glueæ–‡æ¡£: https://docs.aws.amazon.com/glue/
- PySpark API: https://spark.apache.org/docs/latest/api/python/
- AWS CLIå‚è€ƒ: https://docs.aws.amazon.com/cli/
- Glueæœ€ä½³å®è·µ: https://docs.aws.amazon.com/glue/latest/dg/best-practices.html

---

*æœ€åæ›´æ–°: 2025-12-01*
