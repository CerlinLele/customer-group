# AWS Glue运维手册

## 日常操作

### 1. 查看资源状态

```bash
# 查看所有Glue相关资源
terraform state list | grep glue

# 输出示例：
# module.glue_pipeline.aws_glue_catalog_database.databases["customer_raw_db"]
# module.glue_pipeline.aws_glue_crawler.crawlers["customer-data-crawler"]
# module.glue_pipeline.aws_glue_job.jobs["customer-data-cleansing"]
# ...
```

### 2. 查看详细配置

```bash
# 查看特定Job的Terraform配置
terraform state show module.glue_pipeline.aws_glue_job.jobs[\"customer-data-cleansing\"]

# 查看AWS中的实际配置
aws glue get-job --job-name customer-data-cleansing --region us-east-1 | jq .

# 查看特定Crawler的配置
aws glue get-crawler --name customer-data-crawler --region us-east-1 | jq .
```

### 3. 监控资源

```bash
# 查看Crawler运行历史
aws glue get-crawler-metrics --crawler-name customer-data-crawler --region us-east-1

# 查看Job运行历史（最近5次运行）
aws glue get-job-runs --job-name customer-data-cleansing --max-results 5 --region us-east-1

# 查看具体的Job运行详情
aws glue get-job-run --job-name customer-data-cleansing --run-id <run-id> --region us-east-1
```

## 手动触发操作

### 运行Crawler

```bash
# 手动触发Crawler执行
aws glue start-crawler --name customer-data-crawler --region us-east-1

# 查看Crawler状态（READY/RUNNING/STOPPING）
aws glue get-crawler --name customer-data-crawler --region us-east-1 | jq '.Crawler.State'

# 停止正在运行的Crawler
aws glue stop-crawler --name customer-data-crawler --region us-east-1
```

### 运行Job

```bash
# 手动触发Job执行
aws glue start-job-run --job-name customer-data-cleansing --region us-east-1

# 输出示例：
# {
#     "JobRunId": "jr_abcd1234"
# }

# 查看Job运行状态（SUBMITTED/RUNNING/SUCCEEDED/FAILED/STOPPED/TIMEOUT/etc）
aws glue get-job-run --job-name customer-data-cleansing --run-id jr_abcd1234 --region us-east-1

# 使用自定义参数运行Job
aws glue start-job-run \
  --job-name customer-data-cleansing \
  --arguments "--INPUT_DATABASE=customer_raw_db,--OUTPUT_BUCKET=s3://my-bucket/output" \
  --region us-east-1

# 停止正在运行的Job
aws glue batch-stop-job-run --job-name customer-data-cleansing --job-run-ids jr_abcd1234 --region us-east-1
```

## 查看日志

### CloudWatch日志

```bash
# 实时查看Job日志
aws logs tail /aws-glue/jobs/output --follow --region us-east-1

# 查看特定Job的日志
aws logs tail /aws-glue/jobs/output --follow --filter-pattern "customer-data-cleansing" --region us-east-1

# 查看特定时间范围的日志
aws logs filter-log-events \
  --log-group-name /aws-glue/jobs/output \
  --start-time $(date -d '1 hour ago' +%s)000 \
  --region us-east-1

# 查看error级别的日志
aws logs filter-log-events \
  --log-group-name /aws-glue/jobs/output \
  --filter-pattern "ERROR" \
  --region us-east-1
```

### Glue Metrics查看

```bash
# 在CloudWatch中查看Glue指标
aws cloudwatch get-metric-statistics \
  --namespace AWS/Glue \
  --metric-name glue.driver.aggregate.numFailedTasks \
  --dimensions Name=JobName,Value=customer-data-cleansing \
  --start-time 2024-01-01T00:00:00Z \
  --end-time 2024-01-02T00:00:00Z \
  --period 3600 \
  --statistics Sum \
  --region us-east-1
```

## 变更管理

### 添加新Job

#### 步骤1：编写Python脚本

```bash
# 创建新的ETL脚本
vim glue_scripts/new_etl_job.py

# 脚本结构示例
#!/usr/bin/env python3
import sys
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job

args = getResolvedOptions(sys.argv, ['JOB_NAME', 'INPUT_DATABASE', 'OUTPUT_BUCKET'])
sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args['JOB_NAME'], args)

# 您的ETL逻辑
input_dyf = glueContext.create_dynamic_frame.from_catalog(
    database=args['INPUT_DATABASE'],
    table_name='raw_data'
)

# 处理数据...

job.commit()
```

#### 步骤2：上传脚本到S3

```bash
aws s3 cp glue_scripts/new_etl_job.py s3://your-bucket/scripts/ --region us-east-1

# 验证上传
aws s3 ls s3://your-bucket/scripts/new_etl_job.py --region us-east-1
```

#### 步骤3：添加到JSON配置

编辑 `glue_scripts/config/glue_jobs_config.json`：

```json
{
  "glue_jobs": [
    {
      "job_name": "new-etl-job",
      "job_type": "glueetl",
      "description": "新的ETL处理任务",
      "script_location": "s3://your-bucket/scripts/new_etl_job.py",
      "max_capacity": 2,
      "worker_type": "G.1X",
      "glue_version": "4.0",
      "timeout": 30,
      "max_retries": 1,
      "parameters": {
        "--INPUT_DATABASE": "customer_cleaned_db",
        "--OUTPUT_BUCKET": "s3://your-bucket/new_output"
      },
      "schedule": "cron(0 5 * * ? *)",
      "dependencies": ["customer-data-cleansing"]
    }
  ]
}
```

#### 步骤4：应用Terraform变更

```bash
cd infra

# 验证变更
terraform plan

# 应用变更
terraform apply
```

### 修改现有Job配置

```bash
# 1. 编辑JSON配置
vim glue_scripts/config/glue_jobs_config.json

# 2. 如果修改了脚本，需要上传新脚本
aws s3 cp glue_scripts/updated_script.py s3://your-bucket/scripts/ --region us-east-1

# 3. 应用Terraform变更
cd infra
terraform plan
terraform apply

# 4. 注意：正在运行的Job不会立即更新，需要等待完成或手动停止
aws glue batch-stop-job-run --job-name customer-data-cleansing --job-run-ids <run-ids> --region us-east-1
```

### 禁用Job（不删除）

```bash
# 禁用调度Trigger，Job不会自动运行
aws glue update-trigger \
  --name customer-data-cleansing-scheduled-trigger \
  --no-enabled \
  --region us-east-1

# 查看Trigger状态
aws glue get-trigger --name customer-data-cleansing-scheduled-trigger --region us-east-1
```

### 删除Job

```bash
# 1. 从JSON中删除Job配置
# vim glue_scripts/config/glue_jobs_config.json  (移除该Job的定义)

# 2. 应用Terraform变更
cd infra
terraform plan   # 确认会删除该Job
terraform apply  # 执行删除

# 3. 验证删除
aws glue get-job --job-name customer-data-cleansing --region us-east-1  # 应返回空或错误
```

## 监控和告警

### 关键指标

关注以下关键指标：

| 指标 | 正常范围 | 告警阈值 |
|------|---------|----------|
| Job成功率 | > 95% | < 90% |
| Job平均执行时间 | 5-30分钟 | > 60分钟 |
| DPU使用量 | 2-10 DPU | > 20 DPU |
| 错误日志数 | 0-5 | > 10 |
| 数据行数异常 | - | < 预期 50% |

### CloudWatch告警配置

```bash
# 查看已配置的告警
aws cloudwatch describe-alarms --alarm-name-prefix customer-data-pipeline --region us-east-1

# 创建手动告警
aws cloudwatch put-metric-alarm \
  --alarm-name customer-data-pipeline-job-failure \
  --alarm-description "Alert when customer data job fails" \
  --metric-name glue_job_failure \
  --namespace AWS/Glue \
  --statistic Sum \
  --period 300 \
  --threshold 1 \
  --comparison-operator GreaterThanOrEqualToThreshold \
  --evaluation-periods 1 \
  --alarm-actions arn:aws:sns:us-east-1:xxx:glue-alerts \
  --region us-east-1
```

### 告警响应流程

1. **收到CloudWatch告警邮件**
   - 检查告警时间和Job名称
   - 确认是否影响业务

2. **初步诊断**
   ```bash
   # 查看最近的Job运行
   aws glue get-job-runs --job-name <job-name> --max-results 5 --region us-east-1

   # 查看失败的Job详情
   aws glue get-job-run --job-name <job-name> --run-id <failed-run-id> --region us-east-1
   ```

3. **查看日志并定位问题**
   ```bash
   aws logs tail /aws-glue/jobs/output --follow --filter-pattern "<job-name>" --region us-east-1
   ```

4. **问题修复**
   - 若是数据问题：验证数据源
   - 若是脚本问题：修复脚本并上传到S3
   - 若是权限问题：更新IAM策略

5. **重新运行**
   ```bash
   aws glue start-job-run --job-name <job-name> --region us-east-1
   ```

6. **文档和后续行动**
   - 记录问题和解决方案
   - 更新监控和告警规则
   - 分享知识给团队

## 故障排查

### Job运行失败

#### 常见错误及解决方案

**错误1: AccessDenied**

```
Error: AccessDenied: User: xxx is not authorized to perform: glue:GetTable
```

**解决**:
- 检查IAM角色权限是否包含`glue:GetTable`
- 验证Glue Catalog数据库和表是否存在
- 检查S3路径的IAM权限

```bash
# 验证权限
aws iam get-role-policy --role-name GlueCustomerDataRole --policy-name GlueExecutionPolicy

# 验证表是否存在
aws glue get-table --database-name customer_raw_db --name raw_customer_base --region us-east-1
```

**错误2: TableNotFound**

```
Error: Table not found in database customer_raw_db
```

**解决**:
- 运行Crawler以创建表
- 检查Crawler是否成功完成
- 检查表前缀配置

```bash
# 手动运行Crawler
aws glue start-crawler --name customer-data-crawler --region us-east-1

# 等待Crawler完成（查看status）
aws glue get-crawler --name customer-data-crawler --region us-east-1 | jq '.Crawler.State'

# 列出所有表
aws glue get-tables --database-name customer_raw_db --region us-east-1
```

**错误3: ScriptNotFound**

```
Error: s3://my-bucket/scripts/script.py does not exist
```

**解决**:
- 检查脚本是否上传到S3
- 检查S3路径是否正确
- 验证S3权限

```bash
# 检查脚本是否存在
aws s3 ls s3://my-bucket/scripts/ --region us-east-1

# 上传脚本
aws s3 cp glue_scripts/script.py s3://my-bucket/scripts/ --region us-east-1
```

**错误4: Memory不足**

```
Error: Container killed on unmanageable OOM
```

**解决**:
- 增加Job的worker数量或类型
- 优化脚本减少内存使用
- 分片处理大数据

```bash
# 编辑JSON配置，增加max_capacity或worker_type
# "max_capacity": 5,  # 从2增加到5
# "worker_type": "G.2X"  # 从G.1X改为G.2X

# 应用更改
cd infra
terraform apply
```

### Crawler运行失败

#### 检查项

```bash
# 1. 查看Crawler状态
aws glue get-crawler --name customer-data-crawler --region us-east-1

# 2. 查看Crawler的最后运行
aws glue get-crawler-metrics --crawler-name customer-data-crawler --region us-east-1

# 3. 查看S3路径中的数据
aws s3 ls s3://my-bucket/raw/ --recursive --region us-east-1

# 4. 检查IAM权限
aws iam get-role-policy --role-name GlueCustomerDataRole --policy-name GlueExecutionPolicy
```

#### 常见原因

| 原因 | 检查方法 | 解决方案 |
|------|---------|--------|
| S3路径不存在 | `aws s3 ls s3://bucket/path/` | 检查数据源，确保数据已上传 |
| 数据格式不支持 | 查看S3文件扩展名 | 使用CSV/JSON/Parquet等支持的格式 |
| IAM权限不足 | 查看role policy | 添加S3:ListBucket权限 |
| Crawler配置错误 | `aws glue get-crawler` | 检查s3_paths和exclusions配置 |

### Terraform Apply失败

#### 常见错误

**错误: JSON文件不存在**

```
Error: Failed to read configuration: open ../../glue_scripts/config/glue_jobs_config.json: no such file or directory
```

**解决**:
```bash
# 确保从infra目录运行
cd infra

# 检查路径
ls -la ../glue_scripts/config/glue_jobs_config.json
```

**错误: JSON格式不正确**

```
Error: Invalid JSON in config file: invalid character
```

**解决**:
```bash
# 验证JSON
jq . ../glue_scripts/config/glue_jobs_config.json

# 修复格式后重试
terraform validate
```

**错误: 资源已存在**

```
Error: Error creating Glue Crawler: CrawlerAlreadyExistsException
```

**解决**:
```bash
# 导入现有资源
terraform import module.glue_pipeline.aws_glue_crawler.crawlers["customer-data-crawler"] customer-data-crawler

# 重新运行
terraform plan
terraform apply
```

## 性能优化

### 1. Glue Job优化

```bash
# 增加并发度（提高速度，增加成本）
# 编辑JSON，修改max_capacity
"max_capacity": 5  # 默认2，可增至10

# 或使用更高配置的worker
"worker_type": "G.2X"  # 8vCPU vs G.1X的4vCPU
```

### 2. 脚本优化

**优化建议**:
- 使用Spark SQL而非Row-level操作
- 避免小文件，使用分区
- 利用Job Bookmarks实现增量处理
- 使用pushdown predicate减少数据扫描

**脚本示例**:
```python
# 启用分区消除
dyf = glueContext.create_dynamic_frame.from_catalog(
    database="customer_raw_db",
    table_name="raw_data",
    push_down_predicate="year=2024 AND month=1"  # 只读取1月数据
)
```

### 3. Crawler优化

```bash
# 修改爬取频率
# 在JSON中调整schedule
"schedule": "cron(0 2 * * SUN *)"  # 改为每周运行一次

# 排除不必要的路径
"exclusions": ["**/temp/**", "**/_metadata/**", "**/*.bak"]
```

### 4. 数据分区优化

```bash
# 检查分区
aws glue get-partitions --database-name customer_raw_db --table-name raw_data --region us-east-1

# 使用分区列加速查询
SELECT COUNT(*) FROM raw_data WHERE year=2024 AND month=1
```

## 成本管理

### DPU使用量分析

```bash
# 获取Job运行历史和DPU使用
aws glue get-job-runs --job-name customer-data-cleansing --max-results 10 --region us-east-1 | \
  jq '.JobRuns[] | {
    StartedOn,
    CompletedOn,
    ExecutionTime,
    "DPUSeconds": .ExecutionTime
  }'
```

### 成本优化建议

| 优化措施 | 预期节省 | 实施难度 |
|----------|----------|---------|
| 合并小Job | 20-30% | 低 |
| 减少Crawler频率 | 10-15% | 低 |
| 使用更小的Worker类型 | 40-50% | 中 |
| 优化脚本减少运行时间 | 20-40% | 高 |
| 使用Spark优化 | 30-50% | 高 |

## 安全最佳实践

### 1. IAM权限

```bash
# 定期审计IAM权限
aws iam get-role-policy --role-name GlueCustomerDataRole --policy-name GlueExecutionPolicy

# 遵循最小权限原则
# ✓ 只授予必要的权限
# ✗ 避免使用*通配符
```

### 2. S3安全

```bash
# 启用S3加密
aws s3api put-bucket-encryption \
  --bucket my-bucket \
  --server-side-encryption-configuration '{
    "Rules": [{
      "ApplyServerSideEncryptionByDefault": {
        "SSEAlgorithm": "AES256"
      }
    }]
  }'

# 启用版本控制
aws s3api put-bucket-versioning \
  --bucket my-bucket \
  --versioning-configuration Status=Enabled

# 阻止公开访问
aws s3api put-public-access-block \
  --bucket my-bucket \
  --public-access-block-configuration "BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true"
```

### 3. 日志审计

```bash
# 启用CloudTrail
aws cloudtrail start-logging --trail-name my-trail --region us-east-1

# 查询Glue API调用
aws cloudtrail lookup-events \
  --lookup-attributes AttributeKey=ResourceType,AttributeValue=AWS::Glue::Job \
  --region us-east-1
```

## 备份和恢复

### 备份Terraform State

```bash
# 本地备份
cp terraform.tfstate backup/terraform.tfstate.$(date +%Y%m%d_%H%M%S)

# S3备份
aws s3 cp terraform.tfstate s3://backup-bucket/terraform/$(date +%Y%m%d).tfstate

# 启用S3版本控制（推荐）
aws s3api put-bucket-versioning \
  --bucket backup-bucket \
  --versioning-configuration Status=Enabled
```

### 恢复Job配置

```bash
# 从备份恢复JSON配置
cp backup/glue_jobs_config.json.bak glue_scripts/config/glue_jobs_config.json

# 应用Terraform
cd infra
terraform apply

# 验证恢复
terraform state list | grep glue
```

## 合规和治理

### CloudTrail审计

```bash
# 查看所有Glue相关的API调用
aws cloudtrail lookup-events \
  --lookup-attributes AttributeKey=ResourceType,AttributeValue=AWS::Glue::* \
  --max-results 50 \
  --region us-east-1
```

### 标签管理

```bash
# 查看所有带特定标签的资源
aws resourcegroupstaggingapi get-resources \
  --tag-filter Key=Component,Values=DataPipeline \
  --region us-east-1

# 更新标签
aws glue tag-resource \
  --resource-arn arn:aws:glue:us-east-1:xxx:job/customer-data-cleansing \
  --tags-to-add "Owner=DataTeam,CostCenter=123"
```

## 快速参考

### 常用命令

```bash
# 查看所有Jobs
aws glue list-jobs --region us-east-1

# 查看所有Crawlers
aws glue list-crawlers --region us-east-1

# 查看所有Databases
aws glue get-databases --region us-east-1

# 查看所有Triggers
aws glue list-triggers --region us-east-1

# 查看告警
aws cloudwatch list-metrics --namespace AWS/Glue --region us-east-1
```

## 支持和联系

- 技术问题：data-engineering@company.com
- 事件告警：ops-team@company.com
- 文档反馈：docs@company.com
- AWS支持：[AWS Support Console](https://console.aws.amazon.com/support/)
